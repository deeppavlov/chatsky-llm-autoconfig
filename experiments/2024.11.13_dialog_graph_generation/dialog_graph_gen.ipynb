{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle Graph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: graph_dict={'edges': [{'source': 1, 'target': 2, 'utterances': [\"Hi, I'm interested in registering for a gym membership\"]}, {'source': 2, 'target': 3, 'utterances': [\"I'd like a monthly membership\"]}, {'source': 3, 'target': 4, 'utterances': ['Yes, I have my ID with me']}, {'source': 4, 'target': 5, 'utterances': [\"Here's my payment information\"]}, {'source': 5, 'target': 2, 'utterances': [\"I'd like to register another membership\"]}], 'nodes': [{'id': 1, 'label': 'welcome', 'is_start': True, 'utterances': ['Welcome to our gym! How can I assist you with membership registration today?']}, {'id': 2, 'label': 'ask_membership_type', 'is_start': False, 'utterances': ['What type of membership are you interested in?']}, {'id': 3, 'label': 'confirm_id', 'is_start': False, 'utterances': ['A monthly membership. Do you have your ID for verification?']}, {'id': 4, 'label': 'payment', 'is_start': False, 'utterances': ['Great! Please provide your payment information to proceed.']}, {'id': 5, 'label': 'completed', 'is_start': False, 'utterances': ['Thank you for registering! Would you like to register another membership?']}]} graph=<networkx.classes.digraph.DiGraph object at 0x1608729c0> node_mapping={}\n",
      "Sampled dialogue: [Dialogue(messages=[], topic='')]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'model_dump'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 129\u001b[0m\n\u001b[1;32m    126\u001b[0m num_augmentations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Collect dialogues\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m dialogue_collection \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_dialogues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_augmentations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_augmentations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Save dataset\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# saved_path = save_dataset(dialogue_collection, num_augmentations)\u001b[39;00m\n\u001b[1;32m    133\u001b[0m dialogue_collection\n",
      "Cell \u001b[0;32mIn[15], line 53\u001b[0m, in \u001b[0;36mgenerate_dialogues\u001b[0;34m(topics, num_augmentations, model_name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampled dialogue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampled_dialogue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Initialize dialogues array with the sampled dialogue\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m dialogues \u001b[38;5;241m=\u001b[39m [\u001b[43msampled_dialogue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m()]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Generate augmented versions\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_augmentations):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'model_dump'"
     ]
    }
   ],
   "source": [
    "from chatsky_llm_autoconfig.algorithms.dialogue_augmentation import DialogAugmentation\n",
    "from chatsky_llm_autoconfig.algorithms.dialogue_generation import DialogueSampler\n",
    "from chatsky_llm_autoconfig.algorithms.topic_graph_generation import CycleGraphGenerator\n",
    "from chatsky_llm_autoconfig.metrics.llm_metrics import are_triplets_valid\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_dialogues(\n",
    "    topics: List[str], \n",
    "    num_augmentations: int = 2,\n",
    "    model_name: str = \"gpt-4o-mini\"\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Collects dialogues for each topic and returns them in a structured format.\n",
    "    \n",
    "    Args:\n",
    "        topics: List of conversation topics\n",
    "        num_augmentations: Number of augmented dialogues to generate per topic\n",
    "        model_name: Name of the model to use\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing graph, topic, and dialogues for each topic\n",
    "    \"\"\"\n",
    "    # Initialize components\n",
    "    graph_generator = CycleGraphGenerator()\n",
    "    sampler = DialogueSampler()\n",
    "    augmenter = DialogAugmentation()\n",
    "    \n",
    "    model = ChatOpenAI(\n",
    "        model=model_name, \n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"), \n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for topic in topics:\n",
    "        # Generate graph and validate\n",
    "        graph = graph_generator.invoke(topic=topic)\n",
    "        is_valid = are_triplets_valid(graph, model, topic)\n",
    "        \n",
    "        if is_valid[\"value\"]:\n",
    "            print(f\"Graph: {graph}\")\n",
    "            sampled_dialogue = sampler.invoke(graph, 1, -1)\n",
    "            \n",
    "            print(f\"Sampled dialogue: {sampled_dialogue}\")\n",
    "            \n",
    "            # Initialize dialogues array with the sampled dialogue\n",
    "            dialogues = [sampled_dialogue.model_dump()]\n",
    "            \n",
    "            # Generate augmented versions\n",
    "            for _ in range(num_augmentations):\n",
    "                augmented = augmenter.invoke(dialogue=sampled_dialogue, topic=topic)\n",
    "                dialogues.append(augmented.model_dump())\n",
    "            \n",
    "            # Create result entry\n",
    "            result_entry = {\n",
    "                \"graph\": graph.graph_dict,\n",
    "                \"topic\": topic,\n",
    "                \"dialogues\": dialogues\n",
    "            }\n",
    "            \n",
    "            results.append(result_entry)\n",
    "            \n",
    "    return results\n",
    "\n",
    "def save_dataset(data: List[Dict[str, Any]], num_augmentations: int):\n",
    "    \"\"\"\n",
    "    Saves the dataset with a structured filename.\n",
    "    \n",
    "    Args:\n",
    "        data: List of dictionaries containing graph, topic, and dialogues\n",
    "        num_augmentations: Number of augmented dialogues generated\n",
    "    \"\"\"\n",
    "    # Create dataset directory if it doesn't exist\n",
    "    dataset_dir = Path(\"./dataset\")\n",
    "    dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Generate filename with timestamp and dataset info\n",
    "    total_dialogues = 1 + num_augmentations\n",
    "    filename = f\"dialogue_dataset_{len(data)}_topics_{total_dialogues}.json\"\n",
    "    \n",
    "    # Full path for the file\n",
    "    file_path = dataset_dir / filename\n",
    "    \n",
    "    # Convert Graph objects to their dictionary representation\n",
    "    serializable_data = []\n",
    "    for entry in data:\n",
    "        serializable_entry = {\n",
    "            \"graph\": entry[\"graph\"].graph_dict,  # Use graph_dict instead of Graph object\n",
    "            \"topic\": entry[\"topic\"],\n",
    "            \"dialogues\": entry[\"dialogues\"]\n",
    "        }\n",
    "        serializable_data.append(serializable_entry)\n",
    "    \n",
    "    # Save the data\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(serializable_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Dataset saved to: {file_path}\")\n",
    "    return file_path\n",
    "# Example usage\n",
    "topics = [\n",
    "    # \"booking a hotel room\",                    # Travel/Accommodation\n",
    "    # \"scheduling a doctor's appointment\",       # Healthcare\n",
    "    # \"ordering food delivery\",                  # Food Service\n",
    "    # \"tech support for a laptop issue\",         # Technical Support\n",
    "    # \"buying movie tickets\",                    # Entertainment\n",
    "    \"gym membership registration\",             # Fitness\n",
    "    # \"car maintenance service\",                 # Automotive\n",
    "    # \"flight reservation\",                      # Travel\n",
    "    # \"pizza delivery customization\",            # Food Service\n",
    "    # \"hair salon appointment booking\",          # Personal Care\n",
    "    # \"internet service installation\",           # Utilities\n",
    "    # \"banking account assistance\",              # Financial Services\n",
    "    # \"pet grooming appointment\",               # Pet Services\n",
    "    # \"mobile phone plan upgrade\",              # Telecommunications\n",
    "    # \"house cleaning service booking\"           # Home Services\n",
    "]\n",
    "\n",
    "# Number of augmentations (total dialogues will be num_augmentations + 1)\n",
    "num_augmentations = 2\n",
    "\n",
    "# Collect dialogues\n",
    "dialogue_collection = generate_dialogues(topics, num_augmentations=num_augmentations)\n",
    "\n",
    "# Save dataset\n",
    "# saved_path = save_dataset(dialogue_collection, num_augmentations)\n",
    "dialogue_collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
