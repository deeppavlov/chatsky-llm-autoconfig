{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "cycle_graph_generation_prompt = PromptTemplate.from_template(\n",
    "    '''\n",
    "    Create a natural dialogue graph that represents any business conversation with logical cycles.\n",
    "\n",
    "    Here's an example of a clothing store conversation flow:\n",
    "\n",
    "    ```mermaid\n",
    "    graph TD\n",
    "        1[Welcome] -->|\"Looking for jeans\"| 2[Ask Preferences]\n",
    "        2 -->|\"Slim fit, blue\"| 3[Offer Options]\n",
    "        3 -->|\"Like the first one\"| 4[Size Check]\n",
    "        4 -->|\"Size 32\"| 5[Location]\n",
    "        5 -->|\"Try in store\"| 6[Complete]\n",
    "        6 -->|\"Look for something else\"| 2\n",
    "    ```\n",
    "\n",
    "    Example JSON structure:\n",
    "    {{\n",
    "        \"edges\": [\n",
    "            {{ \"source\": 1, \"target\": 2, \"utterances\": [\"I'm looking for jeans\"] }},\n",
    "            {{ \"source\": 2, \"target\": 3, \"utterances\": [\"I'd like slim fit in blue\"] }},\n",
    "            {{ \"source\": 3, \"target\": 4, \"utterances\": [\"I like the first option\"] }},\n",
    "            {{ \"source\": 4, \"target\": 5, \"utterances\": [\"Size 32 please\"] }},\n",
    "            {{ \"source\": 5, \"target\": 6, \"utterances\": [\"I'll try them in store\"] }},\n",
    "            {{ \"source\": 6, \"target\": 2, \"utterances\": [\"I'd like to look for another pair\"] }}\n",
    "        ],\n",
    "        \"nodes\": [\n",
    "            {{ \"id\": 1, \"label\": \"welcome\", \"is_start\": true,\n",
    "              \"utterances\": [\"Welcome to Style Store! How can I help you today?\"] }},\n",
    "            {{ \"id\": 2, \"label\": \"ask_preferences\", \"is_start\": false,\n",
    "              \"utterances\": [\"What style and color are you interested in?\"] }},\n",
    "            {{ \"id\": 3, \"label\": \"offer_options\", \"is_start\": false,\n",
    "              \"utterances\": [\"I have these slim fit blue jeans available. Would you like to see them?\"] }},\n",
    "            {{ \"id\": 4, \"label\": \"check_size\", \"is_start\": false,\n",
    "              \"utterances\": [\"What size would you like?\"] }},\n",
    "            {{ \"id\": 5, \"label\": \"location_preference\", \"is_start\": false,\n",
    "              \"utterances\": [\"Would you like to try them in store or have them delivered?\"] }},\n",
    "            {{ \"id\": 6, \"label\": \"complete\", \"is_start\": false,\n",
    "              \"utterances\": [\"Perfect! The jeans are ready for you. Would you like to look for anything else?\"] }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    Key points:\n",
    "    1. Keep responses natural and contextual\n",
    "    2. Each state should serve a clear purpose\n",
    "    3. Return cycles should make conversational sense\n",
    "\n",
    "    Create a dialogue graph for topic: {topic}\n",
    "    Return only valid JSON matching the format above.\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from chatsky_llm_autoconfig.algorithms.dialogue_augmentation import DialogAugmentation\n",
    "from chatsky_llm_autoconfig.algorithms.dialogue_generation import DialogueSampler\n",
    "from chatsky_llm_autoconfig.algorithms.topic_graph_generation import CycleGraphGenerator\n",
    "from chatsky_llm_autoconfig.metrics.llm_metrics import are_triplets_valid\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_dialogues(\n",
    "    topics: List[str], \n",
    ") -> List[Dict[str, Any]]:\n",
    "\n",
    "    # Initialize components\n",
    "    graph_generator = CycleGraphGenerator(prompt=cycle_graph_generation_prompt)\n",
    "    sampler = DialogueSampler()\n",
    "    \n",
    "    model = ChatOpenAI(\n",
    "        model='gpt-4o', \n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"), \n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for topic in topics:\n",
    "        # Generate graph and validate\n",
    "        graph = graph_generator.invoke(topic=topic)\n",
    "        is_valid = are_triplets_valid(graph, model, topic)\n",
    "        \n",
    "        if is_valid[\"value\"]:\n",
    "            print(f\"Graph: {graph}\")\n",
    "            sampled_dialogue = sampler.invoke(graph, 1, -1)[0]\n",
    "            \n",
    "            print(f\"Sampled dialogue: {sampled_dialogue}\")\n",
    "            \n",
    "            # Initialize dialogues array with the sampled dialogue\n",
    "            dialogues = [sampled_dialogue.model_dump()]\n",
    "        \n",
    "            result_entry = {\n",
    "                \"graph\": graph.graph_dict,\n",
    "                \"topic\": topic,\n",
    "                \"dialogues\": dialogues\n",
    "            }\n",
    "            \n",
    "            results.append(result_entry)\n",
    "            \n",
    "    return results\n",
    "\n",
    "topics = [\n",
    "   \"restaurant table reservation\",\n",
    "   \"tech support troubleshooting\",\n",
    "   \"hotel room booking\", \n",
    "   \"car service appointment\",\n",
    "   \"flight ticket booking\",\n",
    "   \"gym membership registration\",\n",
    "   \"real estate property viewing\",\n",
    "   \"insurance policy purchase\",\n",
    "   \"beauty salon appointment\",\n",
    "   \"bank account opening\"\n",
    "]\n",
    "\n",
    "dialogue_collection = generate_dialogues(topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dialogue_collection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
