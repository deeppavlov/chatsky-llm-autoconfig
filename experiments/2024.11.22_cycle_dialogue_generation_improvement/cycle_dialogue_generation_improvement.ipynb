{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "cycle_graph_generation_prompt = PromptTemplate.from_template(\n",
    "    '''\n",
    "    Create a natural dialogue graph that represents any business conversation with logical cycles.\n",
    "\n",
    "    Here's an example of a clothing store conversation flow:\n",
    "\n",
    "    ```mermaid\n",
    "    graph TD\n",
    "        1[Welcome] -->|\"Looking for jeans\"| 2[Ask Preferences]\n",
    "        2 -->|\"Slim fit, blue\"| 3[Offer Options]\n",
    "        3 -->|\"Like the first one\"| 4[Size Check]\n",
    "        4 -->|\"Size 32\"| 5[Location]\n",
    "        5 -->|\"Try in store\"| 6[Complete]\n",
    "        6 -->|\"Look for something else\"| 2\n",
    "    ```\n",
    "\n",
    "    Example JSON structure:\n",
    "    {{\n",
    "        \"edges\": [\n",
    "            {{ \"source\": 1, \"target\": 2, \"utterances\": [\"I'm looking for jeans\"] }},\n",
    "            {{ \"source\": 2, \"target\": 3, \"utterances\": [\"I'd like slim fit in blue\"] }},\n",
    "            {{ \"source\": 3, \"target\": 4, \"utterances\": [\"I like the first option\"] }},\n",
    "            {{ \"source\": 4, \"target\": 5, \"utterances\": [\"Size 32 please\"] }},\n",
    "            {{ \"source\": 5, \"target\": 6, \"utterances\": [\"I'll try them in store\"] }},\n",
    "            {{ \"source\": 6, \"target\": 2, \"utterances\": [\"I'd like to look for another pair\"] }}\n",
    "        ],\n",
    "        \"nodes\": [\n",
    "            {{ \"id\": 1, \"label\": \"welcome\", \"is_start\": true,\n",
    "              \"utterances\": [\"Welcome to Style Store! How can I help you today?\"] }},\n",
    "            {{ \"id\": 2, \"label\": \"ask_preferences\", \"is_start\": false,\n",
    "              \"utterances\": [\"What style and color are you interested in?\"] }},\n",
    "            {{ \"id\": 3, \"label\": \"offer_options\", \"is_start\": false,\n",
    "              \"utterances\": [\"I have these slim fit blue jeans available. Would you like to see them?\"] }},\n",
    "            {{ \"id\": 4, \"label\": \"check_size\", \"is_start\": false,\n",
    "              \"utterances\": [\"What size would you like?\"] }},\n",
    "            {{ \"id\": 5, \"label\": \"location_preference\", \"is_start\": false,\n",
    "              \"utterances\": [\"Would you like to try them in store or have them delivered?\"] }},\n",
    "            {{ \"id\": 6, \"label\": \"complete\", \"is_start\": false,\n",
    "              \"utterances\": [\"Perfect! The jeans are ready for you. Would you like to look for anything else?\"] }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    Key points:\n",
    "    1. Keep responses natural and contextual\n",
    "    2. Each state should serve a clear purpose\n",
    "    3. Return cycles should make conversational sense\n",
    "    4. Nodes are assistant phrases, edges are user responses. We start with assistant node. We end with assistant node.\n",
    "\n",
    "    Create a dialogue graph for topic: {topic}\n",
    "    Return only valid JSON matching the format above.\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition from ['Our monthly plan includes access to all facilities and group classes. Would you like to proceed with this?'] to ['Great choice! Would you like to proceed with the registration?'] via edge '[\"That sounds good, let's proceed\"]': The transition is invalid because the assistant's target response repeats the question about proceeding with registration, which the user has already agreed to in the edge. The assistant should instead move forward with the registration process rather than asking again.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition from [\"We have state-of-the-art equipment including treadmills, weights, and more. Anything else you'd like to know?\"] to ['We have a variety of facilities. What would you like to know about?'] via edge '['Great, what about personal training?']': The target response does not logically follow the user's question about personal training. The assistant should address the inquiry about personal training rather than providing a generic response about facilities.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition from ['Great choice! Would you like to proceed with the registration?'] to ['What kind of membership are you interested in?'] via edge '['Actually, I have more questions']': The transition is invalid because the user's phrase indicates they have more questions, but the assistant's next phrase assumes the user is ready to discuss membership types. The assistant should address the user's request for more information instead.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition from [\"I've scheduled the viewing. How did you find the property?\"] to ['What did you think of the property?'] via edge '['The house looks great']': The transition is invalid because the target phrase repeats the question about the user's opinion on the property, which has already been addressed by the user's response in the edge. A more logical follow-up would acknowledge the user's positive feedback and perhaps ask for more specific details or discuss next steps.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition from ['What did you think of the property?'] to [\"That's wonderful! Are you ready to make an offer?\"] via edge '[\"I'm ready to make an offer\"]': The transition is invalid because the user's phrase indicates they are already ready to make an offer, but the assistant's next phrase redundantly asks if they are ready to make an offer, which doesn't logically follow the user's statement.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Invalid transition from ['Great choice! Would you like to add any additional coverage or have any other questions?'] to ['What type of insurance policy are you interested in?'] via edge '['Actually, I have another question']': The transition is invalid because the user's phrase indicates they have another question, but the assistant's next phrase does not address this. Instead, it asks about the type of insurance policy, which may not be related to the user's intended question.\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://193.187.173.33:8002/api/providers/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: graph_dict={'edges': [{'source': 1, 'target': 2, 'utterances': [\"Hi, I'd like to book a salon appointment\"]}, {'source': 2, 'target': 3, 'utterances': [\"I'm looking for a haircut\"]}, {'source': 2, 'target': 4, 'utterances': ['I need a manicure']}, {'source': 3, 'target': 5, 'utterances': ['I prefer the stylist I had last time']}, {'source': 3, 'target': 6, 'utterances': ['Any stylist is fine']}, {'source': 4, 'target': 7, 'utterances': [\"I'd like a classic manicure\"]}, {'source': 4, 'target': 8, 'utterances': ['Can I get a gel manicure?']}, {'source': 5, 'target': 9, 'utterances': ['Yes, that works for me']}, {'source': 6, 'target': 9, 'utterances': ['Yes, that time is good']}, {'source': 7, 'target': 9, 'utterances': ['Yes, that time is perfect']}, {'source': 8, 'target': 9, 'utterances': ['Yes, that time works']}, {'source': 9, 'target': 10, 'utterances': [\"No, that's all for now\"]}, {'source': 9, 'target': 2, 'utterances': ['Actually, I need another service']}], 'nodes': [{'id': 1, 'label': 'welcome', 'is_start': True, 'utterances': ['Hello! How can I assist you with your beauty needs today?']}, {'id': 2, 'label': 'service_query', 'is_start': False, 'utterances': ['What service would you like to book?']}, {'id': 3, 'label': 'haircut_preference', 'is_start': False, 'utterances': ['Great choice! Do you have a preferred stylist?']}, {'id': 4, 'label': 'manicure_type', 'is_start': False, 'utterances': ['What type of manicure would you like?']}, {'id': 5, 'label': 'stylist_availability', 'is_start': False, 'utterances': ['Let me check their availability. Does 3 PM on Thursday work for you?']}, {'id': 6, 'label': 'general_availability', 'is_start': False, 'utterances': ['We have an opening at 2 PM on Friday. Does that suit you?']}, {'id': 7, 'label': 'classic_manicure_availability', 'is_start': False, 'utterances': ['We can fit you in at 11 AM on Saturday. Is that okay?']}, {'id': 8, 'label': 'gel_manicure_availability', 'is_start': False, 'utterances': ['We have a slot at 1 PM on Monday. Does that work for you?']}, {'id': 9, 'label': 'confirmation', 'is_start': False, 'utterances': ['Your appointment is confirmed. Would you like to book any other services?']}, {'id': 10, 'label': 'farewell', 'is_start': False, 'utterances': ['Thank you for booking with us! We look forward to seeing you.']}]} graph=<networkx.classes.digraph.DiGraph object at 0x11bb2c2c0> node_mapping={}\n",
      "Sampled dialogue: assistant: Hello! How can I assist you with your beauty needs today?\n",
      "user: Hi, I'd like to book a salon appointment\n",
      "assistant: What service would you like to book?\n",
      "user: I need a manicure\n",
      "assistant: What type of manicure would you like?\n",
      "user: Can I get a gel manicure?\n",
      "assistant: We have a slot at 1 PM on Monday. Does that work for you?\n",
      "user: Yes, that time works\n",
      "assistant: Your appointment is confirmed. Would you like to book any other services?\n",
      "user: Actually, I need another service\n",
      "assistant: What service would you like to book?\n",
      "user: I'm looking for a haircut\n",
      "assistant: Great choice! Do you have a preferred stylist?\n",
      "user: Any stylist is fine\n",
      "assistant: We have an opening at 2 PM on Friday. Does that suit you?\n",
      "user: Yes, that time is good\n",
      "assistant: Your appointment is confirmed. Would you like to book any other services?\n",
      "user: No, that's all for now\n",
      "assistant: Thank you for booking with us! We look forward to seeing you.\n"
     ]
    }
   ],
   "source": [
    "from chatsky_llm_autoconfig.algorithms.dialogue_generation import DialogueSampler\n",
    "from chatsky_llm_autoconfig.algorithms.topic_graph_generation import CycleGraphGenerator\n",
    "from chatsky_llm_autoconfig.metrics.llm_metrics import are_triplets_valid\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def generate_dialogues(\n",
    "    topics: List[str], \n",
    ") -> List[Dict[str, Any]]:\n",
    "\n",
    "    # Initialize components\n",
    "    graph_generator = CycleGraphGenerator(prompt=cycle_graph_generation_prompt)\n",
    "    sampler = DialogueSampler()\n",
    "    \n",
    "    model = ChatOpenAI(\n",
    "        model='gpt-4o', \n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"), \n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for topic in topics:\n",
    "        # Generate graph and validate\n",
    "        graph = graph_generator.invoke(topic=topic)\n",
    "        is_valid = are_triplets_valid(graph, model, topic)\n",
    "        \n",
    "        if is_valid[\"value\"]:\n",
    "            print(f\"Graph: {graph}\")\n",
    "            sampled_dialogue = sampler.invoke(graph, 1, -1)[0]\n",
    "            \n",
    "            print(f\"Sampled dialogue: {sampled_dialogue}\")\n",
    "            \n",
    "            # Initialize dialogues array with the sampled dialogue\n",
    "            dialogues = [sampled_dialogue.model_dump()]\n",
    "        \n",
    "            result_entry = {\n",
    "                \"graph\": graph.graph_dict,\n",
    "                \"topic\": topic,\n",
    "                \"dialogues\": dialogues\n",
    "            }\n",
    "            \n",
    "            results.append(result_entry)\n",
    "            \n",
    "    return results\n",
    "\n",
    "topics = [\n",
    "#    \"restaurant table reservation\",\n",
    "#    \"tech support troubleshooting\",\n",
    "#    \"hotel room booking\", \n",
    "#    \"car service appointment\",\n",
    "#    \"flight ticket booking\",\n",
    "   \"gym membership registration\",\n",
    "   \"real estate property viewing\",\n",
    "   \"insurance policy purchase\",\n",
    "   \"beauty salon appointment\",\n",
    "#    \"bank account opening\"\n",
    "]\n",
    "\n",
    "dialogue_collection = generate_dialogues(topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dialogue_collection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
